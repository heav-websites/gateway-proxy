global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'docker-targets'
    docker_sd_configs:
      - host: tcp://docker-proxy:2375
    relabel_configs:
      # 1. Filter: Keep only containers explicitly labeled for Prometheus scraping
      - source_labels: [__meta_docker_container_label_prometheus_scrape]
        regex: "true"
        action: keep

      # 2. Set 'job' label: Use the Docker Compose service name or container name
      - source_labels: [__meta_docker_container_label_com_docker_compose_service, __meta_docker_container_name]
        regex: "(.*);/(.*)"
        target_label: job
        replacement: "${1}"
        action: replace # Try to use the compose service name, fallback to container name

      # 3. Set 'instance' label: Use the container name for unique identification
      - source_labels: [__meta_docker_container_name]
        regex: "/(.*)"
        target_label: instance
        replacement: "${1}"

      # 4. Set '__address__': Combine container IP and labeled port (defaulting to 80 if no label)
      #    __meta_docker_container_ip gives the IP of the container within the default bridge network.
      - source_labels: [__meta_docker_container_ip, __meta_docker_container_label_prometheus_port]
        regex: "([^;]+);([^;]+)" # IP;PORT
        target_label: __address__
        replacement: "${1}:${2}"
        action: replace

      # 5. Set '__metrics_path__': Use labeled path (defaulting to /metrics)
      - source_labels: [__meta_docker_container_label_prometheus_path]
        regex: "(.+)"
        target_label: __metrics_path__
        replacement: "${1}"
        action: replace
      # If no prometheus.path label, it defaults to /metrics automatically, no need for another rule
